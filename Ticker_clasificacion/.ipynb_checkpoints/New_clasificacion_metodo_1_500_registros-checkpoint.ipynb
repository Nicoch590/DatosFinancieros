{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67b2462d",
   "metadata": {},
   "source": [
    "# Metodo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7982c5fd",
   "metadata": {},
   "source": [
    "Objetivo: clasificar noticias segun ticker o compa√±ia a la que hacen referencia.\n",
    "\n",
    "Realizamos una reduccion del dataset original, tomando solo aquellos tickers que tienen mas de 500 registros, preprocesamos con countvectorizer para obtener bolsa de palabras, realizamos una reduccion de dimensionalidad, probamos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0bd2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "np.set_printoptions(precision=4,suppress=True)  # no usar notacion \"e\"\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2876add",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv(\"Datasets/news_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4837df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b23e6119",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ticker</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>content</th>\n",
       "      <th>release_date</th>\n",
       "      <th>provider</th>\n",
       "      <th>url</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221515</td>\n",
       "      <td>NIO</td>\n",
       "      <td>Why Shares of Chinese Electric Car Maker NIO A...</td>\n",
       "      <td>news</td>\n",
       "      <td>What s happening\\nShares of Chinese electric c...</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>The Motley Fool</td>\n",
       "      <td>https://invst.ly/pigqi</td>\n",
       "      <td>2060327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>221516</td>\n",
       "      <td>NIO</td>\n",
       "      <td>NIO only consumer gainer  Workhorse Group amon...</td>\n",
       "      <td>news</td>\n",
       "      <td>Gainers  NIO  NYSE NIO   7  \\nLosers  MGP Ingr...</td>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>https://invst.ly/pje9c</td>\n",
       "      <td>2062196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221517</td>\n",
       "      <td>NIO</td>\n",
       "      <td>NIO leads consumer gainers  Beyond Meat and Ma...</td>\n",
       "      <td>news</td>\n",
       "      <td>Gainers  NIO  NYSE NIO   14   Village Farms In...</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>https://invst.ly/pifmv</td>\n",
       "      <td>2060249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>221518</td>\n",
       "      <td>NIO</td>\n",
       "      <td>NIO  NVAX among premarket gainers</td>\n",
       "      <td>news</td>\n",
       "      <td>Cemtrex  NASDAQ CETX   85  after FY results \\n...</td>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>https://invst.ly/picu8</td>\n",
       "      <td>2060039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221519</td>\n",
       "      <td>NIO</td>\n",
       "      <td>PLUG  NIO among premarket gainers</td>\n",
       "      <td>news</td>\n",
       "      <td>aTyr Pharma  NASDAQ LIFE   63  on Kyorin Pharm...</td>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>https://seekingalpha.com/news/3529772-plug-nio...</td>\n",
       "      <td>2053096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id ticker                                              title category  \\\n",
       "0  221515    NIO  Why Shares of Chinese Electric Car Maker NIO A...     news   \n",
       "1  221516    NIO  NIO only consumer gainer  Workhorse Group amon...     news   \n",
       "2  221517    NIO  NIO leads consumer gainers  Beyond Meat and Ma...     news   \n",
       "3  221518    NIO                  NIO  NVAX among premarket gainers     news   \n",
       "4  221519    NIO                  PLUG  NIO among premarket gainers     news   \n",
       "\n",
       "                                             content release_date  \\\n",
       "0  What s happening\\nShares of Chinese electric c...   2020-01-15   \n",
       "1  Gainers  NIO  NYSE NIO   7  \\nLosers  MGP Ingr...   2020-01-18   \n",
       "2  Gainers  NIO  NYSE NIO   14   Village Farms In...   2020-01-15   \n",
       "3  Cemtrex  NASDAQ CETX   85  after FY results \\n...   2020-01-15   \n",
       "4  aTyr Pharma  NASDAQ LIFE   63  on Kyorin Pharm...   2020-01-06   \n",
       "\n",
       "          provider                                                url  \\\n",
       "0  The Motley Fool                             https://invst.ly/pigqi   \n",
       "1    Seeking Alpha                             https://invst.ly/pje9c   \n",
       "2    Seeking Alpha                             https://invst.ly/pifmv   \n",
       "3    Seeking Alpha                             https://invst.ly/picu8   \n",
       "4    Seeking Alpha  https://seekingalpha.com/news/3529772-plug-nio...   \n",
       "\n",
       "   article_id  \n",
       "0     2060327  \n",
       "1     2062196  \n",
       "2     2060249  \n",
       "3     2060039  \n",
       "4     2053096  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd07de9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 221513 entries, 0 to 221512\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   id            221513 non-null  int64 \n",
      " 1   ticker        221513 non-null  object\n",
      " 2   title         221513 non-null  object\n",
      " 3   category      221513 non-null  object\n",
      " 4   content       221505 non-null  object\n",
      " 5   release_date  221513 non-null  object\n",
      " 6   provider      221513 non-null  object\n",
      " 7   url           221513 non-null  object\n",
      " 8   article_id    221513 non-null  int64 \n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 15.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a71992cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AAPL     20231\n",
       "MSFT      8110\n",
       "BAC       7409\n",
       "AMZN      6330\n",
       "NWSA      5914\n",
       "         ...  \n",
       "BUSE         1\n",
       "CRMBQ        1\n",
       "CHCI         1\n",
       "EDMCQ        1\n",
       "CART         1\n",
       "Name: ticker, Length: 802, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ticker.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee508e0c",
   "metadata": {},
   "source": [
    "Vemos que hay registros que contienen un unico valor, realizamos una reduccion a los que poseen al menos 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "61d4338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduccion \n",
    "registros=500\n",
    "ticker_count = df.ticker.value_counts().reset_index().rename(columns={'index':'ticker','ticker':'count'})\n",
    "ticker_reduccion = list(ticker_count[ticker_count['count']>registros].ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e9aa1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ticker_reduccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9bfc0ba9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134098, 9)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_red = df[df.ticker.isin(ticker_reduccion)]\n",
    "df_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5a652f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 134098 entries, 76 to 221512\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   id            134098 non-null  int64 \n",
      " 1   ticker        134098 non-null  object\n",
      " 2   title         134098 non-null  object\n",
      " 3   category      134098 non-null  object\n",
      " 4   content       134092 non-null  object\n",
      " 5   release_date  134098 non-null  object\n",
      " 6   provider      134098 non-null  object\n",
      " 7   url           134098 non-null  object\n",
      " 8   article_id    134098 non-null  int64 \n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 10.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df_red.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb27374",
   "metadata": {},
   "source": [
    "Existen 6 valores nulos, los descartamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b5ef3401",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample=df_red.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1d9621",
   "metadata": {},
   "source": [
    "Concatenamos los valores de las columnas que consideramos relevantes para la clasificacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60cbd947",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df_sample['title']+' '+df_sample['content']+' ' + df_sample['category']+' '+df_sample['provider']\n",
    "y=df_sample['ticker']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd9f872",
   "metadata": {},
   "source": [
    "## Division Entrenamiento - Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd21fd0",
   "metadata": {},
   "source": [
    "Realizamos una division de los datos en entrenamientos y test, utilizamos un 80% entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8904391d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c714d8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((107273,), (26819,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c50f2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((107273,), (26819,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca47ecf",
   "metadata": {},
   "source": [
    "## Preprocesamiento CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66d637d",
   "metadata": {},
   "source": [
    "Transformamos el texto en bolsa de palabras, utilizando CountVectorizer con su preprocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "849393c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "81c4553a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect.fit(X_train)\n",
    "V_X_train=vect.transform(X_train)\n",
    "V_X_test=vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f31f7822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((107273, 230576), (26819, 230576))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_X_train.shape , V_X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40f9d27",
   "metadata": {},
   "source": [
    "## Reduccion dimensionalidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300a8104",
   "metadata": {},
   "source": [
    "Realizamos una reduccion de las dimensiones, ya que la matriz de salida de Countvectorizer posee mas de 200 mil features. Utilizamos TruncatedSVD, una descomposicion que permite trabajar con matrices esparsas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6044650c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.777199960268369\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
    "\n",
    "svd.fit(V_X_train)\n",
    "\n",
    "#print(svd.explained_variance_ratio_)\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "#print(svd.singular_values_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6424d7",
   "metadata": {},
   "source": [
    "Las primeras 100 componentes explican el 0.77 de la varianza, nos quedamos con estas componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "e0602e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_X_train_SVD_nn = svd.transform(V_X_train)\n",
    "V_X_test_SVD_nn = svd.transform(V_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f9f39f",
   "metadata": {},
   "source": [
    "Normalizamos las matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9405769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "transformer = Normalizer().fit(V_X_train_SVD_nn)  # fit does nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8b0182fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_X_train_SVD = transformer.transform(V_X_train_SVD_nn)\n",
    "V_X_test_SVD=transformer.transform(V_X_test_SVD_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9e3f79f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8628,  0.1112, -0.0565, ...,  0.0353,  0.0022, -0.0026],\n",
       "       [ 0.9095,  0.017 ,  0.0409, ...,  0.0251, -0.018 , -0.0289],\n",
       "       [ 0.9179,  0.0199,  0.1447, ..., -0.0369, -0.0194,  0.0313],\n",
       "       ...,\n",
       "       [ 0.9084, -0.1474,  0.1291, ..., -0.0171, -0.0136, -0.0041],\n",
       "       [ 0.8433,  0.0656, -0.3328, ..., -0.0104, -0.0138, -0.014 ],\n",
       "       [ 0.8673,  0.0556, -0.0647, ..., -0.0143,  0.0001, -0.0055]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_X_train_SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de6c91c",
   "metadata": {},
   "source": [
    "## Prueba de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e640b31",
   "metadata": {},
   "source": [
    "### Modelos lineales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac13227",
   "metadata": {},
   "source": [
    "Utilizamos SGDClassifier para probar modelos SVM y logisticos, y RandomizedSearchCV, para probar hiperparametros de manera aleatoria y realizar Cross-Validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8bf98fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.fixes import loguniform\n",
    "from scipy import stats\n",
    "\n",
    "param_dist = {\n",
    "    'loss': [\n",
    "        'hinge',        # SVM\n",
    "        'log',          # logistic regression\n",
    "        ],\n",
    "    'alpha': loguniform(1e-4, 1e2),  # de 0.0001 a 100.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "63009a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=SGDClassifier(random_state=0), n_iter=20,\n",
       "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000022F00F7A4E0>,\n",
       "                                        'loss': ['hinge', 'log']},\n",
       "                   random_state=0)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "model = SGDClassifier(random_state=0)\n",
    "\n",
    "cv = RandomizedSearchCV(model, param_dist, n_iter=20, cv=3, random_state=0)\n",
    "cv.fit(V_X_train_SVD, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a2e5b13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hinge</td>\n",
       "      <td>0.551293</td>\n",
       "      <td>0.410849</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hinge</td>\n",
       "      <td>0.0422205</td>\n",
       "      <td>0.422707</td>\n",
       "      <td>0.004925</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hinge</td>\n",
       "      <td>0.000218916</td>\n",
       "      <td>0.433352</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hinge</td>\n",
       "      <td>0.0199825</td>\n",
       "      <td>0.435739</td>\n",
       "      <td>0.007315</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>hinge</td>\n",
       "      <td>0.000512444</td>\n",
       "      <td>0.434313</td>\n",
       "      <td>0.008321</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_loss  param_alpha  mean_test_score  std_test_score  rank_test_score\n",
       "3       hinge     0.551293         0.410849        0.003438                5\n",
       "4       hinge    0.0422205         0.422707        0.004925                4\n",
       "5       hinge  0.000218916         0.433352        0.005771                3\n",
       "6       hinge    0.0199825         0.435739        0.007315                1\n",
       "16      hinge  0.000512444         0.434313        0.008321                2"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = cv.cv_results_\n",
    "df_result_lineal = pd.DataFrame(results)\n",
    "df_result_lineal[df_result_lineal.rank_test_score<6][['param_loss', 'param_alpha', 'mean_test_score', 'std_test_score', 'rank_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "3844959a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01998246739232945, 'loss': 'hinge'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a242492",
   "metadata": {},
   "source": [
    "### Arbol de decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "24c5f310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(1, 10)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "af3d9ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist_dtree = {\n",
    "    \n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': range(1,4)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "92653c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nico Ch\\.conda\\envs\\diplodatos-ayvd\\lib\\site-packages\\sklearn\\model_selection\\_search.py:289: UserWarning: The total space of parameters 6 is smaller than n_iter=10. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  % (grid_size, self.n_iter, grid_size), UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=DecisionTreeClassifier(random_state=0),\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': range(1, 4)},\n",
       "                   random_state=0)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "cv_dt = RandomizedSearchCV(dtree, param_dist_dtree, n_iter=10, cv=3, random_state=0)\n",
    "\n",
    "cv_dt.fit(V_X_train_SVD, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "eca23d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.151389</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.159155</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>0.176885</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.151641</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.169567</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>0.175207</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_max_depth param_criterion  mean_test_score  std_test_score  \\\n",
       "0               1            gini         0.151389        0.000012   \n",
       "1               2            gini         0.159155        0.000082   \n",
       "2               3            gini         0.176885        0.000261   \n",
       "3               1         entropy         0.151641        0.000372   \n",
       "4               2         entropy         0.169567        0.000471   \n",
       "5               3         entropy         0.175207        0.000449   \n",
       "\n",
       "   rank_test_score  \n",
       "0                6  \n",
       "1                4  \n",
       "2                1  \n",
       "3                5  \n",
       "4                3  \n",
       "5                2  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_tree = cv_dt.cv_results_\n",
    "df_result_tree = pd.DataFrame(results_tree)\n",
    "df_result_tree[['param_max_depth', 'param_criterion', 'mean_test_score', 'std_test_score', 'rank_test_score']] #[df_result_lineal.rank_test_score<6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e89d290",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2cafd95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, random_state=2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "clf = ensemble.RandomForestClassifier(n_estimators=10, random_state=2)\n",
    "clf.fit(V_X_train_SVD, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "031ff080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       1.00      1.00      1.00       836\n",
      "        AAPL       0.99      1.00      0.99     16240\n",
      "         ADP       1.00      1.00      1.00       433\n",
      "         AGN       0.99      1.00      0.99       672\n",
      "        AMGN       1.00      1.00      1.00       565\n",
      "        AMZN       0.99      1.00      0.99      5092\n",
      "        AVGO       1.00      0.99      0.99       410\n",
      "          BA       0.99      1.00      1.00      4691\n",
      "         BAC       0.99      1.00      0.99      5957\n",
      "         BHC       1.00      1.00      1.00       425\n",
      "         BKR       1.00      1.00      1.00       690\n",
      "         BLK       1.00      1.00      1.00       941\n",
      "           C       1.00      0.99      1.00      1677\n",
      "         CAJ       1.00      1.00      1.00       432\n",
      "         CAT       1.00      1.00      1.00       679\n",
      "         CME       1.00      1.00      1.00       919\n",
      "         CMG       1.00      0.99      1.00       812\n",
      "         CVX       1.00      1.00      1.00       873\n",
      "         DAL       1.00      0.99      0.99       473\n",
      "         DIS       0.99      0.99      0.99      2302\n",
      "         EFX       1.00      0.99      1.00       686\n",
      "       ENGIE       1.00      1.00      1.00       468\n",
      "         FCX       1.00      0.99      1.00       492\n",
      "         FDX       1.00      0.99      1.00       499\n",
      "          GE       1.00      1.00      1.00      1668\n",
      "          GM       0.99      1.00      1.00      1665\n",
      "       GOOGL       1.00      1.00      1.00      4155\n",
      "          GS       1.00      1.00      1.00      3624\n",
      "          HD       1.00      1.00      1.00       498\n",
      "         IBM       1.00      1.00      1.00      1001\n",
      "         ICE       1.00      0.99      1.00       498\n",
      "        INTC       1.00      0.99      0.99      2537\n",
      "         JNJ       1.00      1.00      1.00       622\n",
      "         JPM       1.00      0.99      0.99      2072\n",
      "         JWN       1.00      1.00      1.00       417\n",
      "          KO       1.00      0.99      0.99      1094\n",
      "         LMT       1.00      0.99      0.99       746\n",
      "         MRK       1.00      1.00      1.00       460\n",
      "          MS       1.00      0.99      1.00      1989\n",
      "        MSFT       1.00      0.99      0.99      6453\n",
      "          MU       1.00      0.98      0.99      1551\n",
      "        NFLX       0.99      0.99      0.99      3009\n",
      "         NKE       1.00      0.99      1.00       595\n",
      "        NLOK       1.00      0.99      1.00       402\n",
      "        NWSA       1.00      1.00      1.00      4667\n",
      "         PFE       1.00      0.99      1.00       427\n",
      "          PG       1.00      1.00      1.00       457\n",
      "         PGR       1.00      0.99      1.00       555\n",
      "        SBUX       1.00      0.99      1.00       690\n",
      "         SLB       1.00      0.99      1.00       635\n",
      "         SNE       1.00      0.99      1.00       455\n",
      "          SO       1.00      1.00      1.00       778\n",
      "           T       1.00      0.99      1.00       596\n",
      "         TGT       1.00      0.99      1.00      2942\n",
      "          TM       1.00      0.99      0.99      1485\n",
      "        TSLA       1.00      0.99      0.99      3457\n",
      "        UBER       1.00      0.99      1.00       975\n",
      "        UBSG       1.00      0.99      1.00       471\n",
      "          VZ       1.00      0.99      1.00       759\n",
      "         WFC       1.00      0.99      0.99      1093\n",
      "         WMB       1.00      0.99      1.00      1183\n",
      "         WMT       1.00      0.99      0.99      1037\n",
      "         XOM       1.00      1.00      1.00      2291\n",
      "\n",
      "    accuracy                           0.99    107273\n",
      "   macro avg       1.00      0.99      1.00    107273\n",
      "weighted avg       1.00      0.99      0.99    107273\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_pred_train = clf.predict(V_X_train_SVD)\n",
    "print(classification_report(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bbe85c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicts_test_RF = clf.predict(V_X_test_SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "3ba6b9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          AA       0.08      0.12      0.10       243\n",
      "        AAPL       0.34      0.77      0.47      3991\n",
      "         ADP       0.21      0.16      0.18       110\n",
      "         AGN       0.06      0.06      0.06       151\n",
      "        AMGN       0.23      0.25      0.24       123\n",
      "        AMZN       0.32      0.46      0.38      1238\n",
      "        AVGO       0.21      0.10      0.14       107\n",
      "          BA       0.52      0.65      0.58      1188\n",
      "         BAC       0.27      0.42      0.33      1451\n",
      "         BHC       0.56      0.22      0.31       101\n",
      "         BKR       0.52      0.57      0.54       164\n",
      "         BLK       0.17      0.08      0.11       245\n",
      "           C       0.09      0.06      0.07       404\n",
      "         CAJ       0.41      0.27      0.33       114\n",
      "         CAT       0.20      0.08      0.11       193\n",
      "         CME       0.43      0.27      0.33       234\n",
      "         CMG       0.11      0.04      0.05       221\n",
      "         CVX       0.23      0.15      0.18       232\n",
      "         DAL       0.17      0.05      0.08       124\n",
      "         DIS       0.38      0.30      0.33       573\n",
      "         EFX       0.36      0.10      0.16       187\n",
      "       ENGIE       0.95      0.77      0.85       129\n",
      "         FCX       0.14      0.05      0.07       126\n",
      "         FDX       0.08      0.02      0.03       110\n",
      "          GE       0.23      0.14      0.17       377\n",
      "          GM       0.53      0.50      0.51       424\n",
      "       GOOGL       0.36      0.34      0.35      1016\n",
      "          GS       0.16      0.14      0.15       889\n",
      "          HD       0.36      0.09      0.14       116\n",
      "         IBM       0.27      0.09      0.14       248\n",
      "         ICE       0.27      0.06      0.10       132\n",
      "        INTC       0.23      0.13      0.17       651\n",
      "         JNJ       0.21      0.09      0.13       141\n",
      "         JPM       0.18      0.09      0.12       528\n",
      "         JWN       0.12      0.02      0.03       123\n",
      "          KO       0.28      0.11      0.16       273\n",
      "         LMT       0.25      0.08      0.12       191\n",
      "         MRK       0.28      0.11      0.16       115\n",
      "          MS       0.18      0.07      0.10       509\n",
      "        MSFT       0.41      0.37      0.39      1657\n",
      "          MU       0.22      0.06      0.10       376\n",
      "        NFLX       0.64      0.42      0.51       797\n",
      "         NKE       0.14      0.03      0.05       158\n",
      "        NLOK       0.30      0.03      0.05       111\n",
      "        NWSA       0.47      0.52      0.49      1247\n",
      "         PFE       0.25      0.04      0.07       118\n",
      "          PG       0.23      0.06      0.09       127\n",
      "         PGR       0.66      0.34      0.45       142\n",
      "        SBUX       0.22      0.03      0.06       155\n",
      "         SLB       0.35      0.14      0.20       153\n",
      "         SNE       0.70      0.16      0.26       129\n",
      "          SO       0.24      0.08      0.12       201\n",
      "           T       0.26      0.06      0.10       163\n",
      "         TGT       0.31      0.20      0.24       747\n",
      "          TM       0.35      0.19      0.24       335\n",
      "        TSLA       0.66      0.49      0.57       826\n",
      "        UBER       0.21      0.05      0.08       247\n",
      "        UBSG       0.43      0.08      0.14       121\n",
      "          VZ       0.48      0.16      0.25       182\n",
      "         WFC       0.34      0.07      0.12       266\n",
      "         WMB       0.50      0.34      0.41       299\n",
      "         WMT       0.16      0.03      0.05       230\n",
      "         XOM       0.38      0.27      0.31       540\n",
      "\n",
      "    accuracy                           0.35     26819\n",
      "   macro avg       0.32      0.20      0.22     26819\n",
      "weighted avg       0.34      0.35      0.32     26819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_predicts_test_RF))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0452e7ce",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1880b9d",
   "metadata": {},
   "source": [
    "Observando las metricas de train podemos ver que la mayor accuracy es en modelos lineales, siendo de aprox 0.45, random forest obtiene 0.99 overfiteando sobre los datos de entrenamiento, ya que al realizar predicciones sobre el conjunto de test su accuracy cae a 0.35.\n",
    "Probamos cambiando el metodo de preprocesamiento en Metodo 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cd0ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-diplodatos-ayvd] *",
   "language": "python",
   "name": "conda-env-.conda-diplodatos-ayvd-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
